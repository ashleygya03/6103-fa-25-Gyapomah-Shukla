{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d08a80b",
   "metadata": {},
   "source": [
    "# Project Title: Proactive Container Scaling Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f9979",
   "metadata": {},
   "source": [
    "## By: Ashley G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661d6dfd",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Your project title, names, and date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33ae12",
   "metadata": {},
   "source": [
    "## 2. Setup and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86348634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The random seed\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(random_seed)\n",
    "import pandas as pd\n",
    "from wooldridge import dataWoo\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sklearn.datasets\n",
    "from sklearn.inspection import DecisionBoundaryDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1b434c",
   "metadata": {},
   "source": [
    "### 2.1. Load and Inspect Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c95c7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perf=pd.read_csv('kubernetes_performance_metrics_dataset.csv')\n",
    "df_resource=pd.read_csv('kubernetes_resource_allocation_dataset.csv')\n",
    "\n",
    "df_perf['timestamp'] = pd.to_datetime(df_perf['timestamp'], format='%m/%d/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b5b34bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timestamp',\n",
       " 'pod_name',\n",
       " 'namespace',\n",
       " 'cpu_allocation_efficiency',\n",
       " 'memory_allocation_efficiency',\n",
       " 'disk_io',\n",
       " 'network_latency',\n",
       " 'node_temperature',\n",
       " 'node_cpu_usage',\n",
       " 'node_memory_usage',\n",
       " 'event_type',\n",
       " 'event_message',\n",
       " 'scaling_event',\n",
       " 'pod_lifetime_seconds']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perf.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f6ba8652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pod_name',\n",
       " 'namespace',\n",
       " 'cpu_request',\n",
       " 'cpu_limit',\n",
       " 'memory_request',\n",
       " 'memory_limit',\n",
       " 'cpu_usage',\n",
       " 'memory_usage',\n",
       " 'node_name',\n",
       " 'pod_status',\n",
       " 'restart_count',\n",
       " 'uptime_seconds',\n",
       " 'deployment_strategy',\n",
       " 'scaling_policy',\n",
       " 'network_bandwidth_usage']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resource.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ec0f0",
   "metadata": {},
   "source": [
    "### 2.2 Data Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d6025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows after merge: 15000\n",
      "Columns after merge: ['timestamp', 'pod_name', 'namespace', 'cpu_allocation_efficiency', 'memory_allocation_efficiency', 'disk_io', 'network_latency', 'node_temperature', 'node_cpu_usage', 'node_memory_usage', 'event_type', 'event_message', 'scaling_event', 'pod_lifetime_seconds', 'memory_usage', 'cpu_limit', 'memory_limit', 'cpu_usage', 'deployment_strategy', 'scaling_policy', 'cpu_request', 'memory_request']\n",
      "\n",
      "SUCCESS: The critical 'cpu_usage' column is present.\n"
     ]
    }
   ],
   "source": [
    "# Select key configuration columns from the resource allocation data\n",
    "resource_cols_to_keep = [\n",
    "    'pod_name', 'memory_usage', 'cpu_limit', 'memory_limit', 'cpu_usage',\n",
    "    'deployment_strategy', 'scaling_policy', 'cpu_request', 'memory_request'\n",
    "]\n",
    "\n",
    "# Merge the datasets using a left join\n",
    "df_raw_merged = pd.merge(\n",
    "    df_perf,\n",
    "    df_resource[resource_cols_to_keep],\n",
    "    on=['pod_name'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Total rows after merge: {len(df_raw_merged)}\")\n",
    "print(f\"Columns after merge: {df_raw_merged.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0e70d0",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee09b38",
   "metadata": {},
   "source": [
    "### 3.1. Identify and Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9178ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df_raw_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a585dcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 22 columns):\n",
      " #   Column                        Non-Null Count  Dtype         \n",
      "---  ------                        --------------  -----         \n",
      " 0   timestamp                     15000 non-null  datetime64[ns]\n",
      " 1   pod_name                      15000 non-null  object        \n",
      " 2   namespace                     15000 non-null  object        \n",
      " 3   cpu_allocation_efficiency     15000 non-null  float64       \n",
      " 4   memory_allocation_efficiency  15000 non-null  float64       \n",
      " 5   disk_io                       15000 non-null  float64       \n",
      " 6   network_latency               15000 non-null  float64       \n",
      " 7   node_temperature              15000 non-null  float64       \n",
      " 8   node_cpu_usage                15000 non-null  float64       \n",
      " 9   node_memory_usage             15000 non-null  float64       \n",
      " 10  event_type                    15000 non-null  object        \n",
      " 11  event_message                 15000 non-null  object        \n",
      " 12  scaling_event                 15000 non-null  bool          \n",
      " 13  pod_lifetime_seconds          15000 non-null  int64         \n",
      " 14  memory_usage                  15000 non-null  float64       \n",
      " 15  cpu_limit                     15000 non-null  float64       \n",
      " 16  memory_limit                  15000 non-null  float64       \n",
      " 17  cpu_usage                     15000 non-null  float64       \n",
      " 18  deployment_strategy           15000 non-null  object        \n",
      " 19  scaling_policy                15000 non-null  object        \n",
      " 20  cpu_request                   15000 non-null  float64       \n",
      " 21  memory_request                15000 non-null  float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(13), int64(1), object(6)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd7faae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>cpu_allocation_efficiency</th>\n",
       "      <th>memory_allocation_efficiency</th>\n",
       "      <th>disk_io</th>\n",
       "      <th>network_latency</th>\n",
       "      <th>node_temperature</th>\n",
       "      <th>node_cpu_usage</th>\n",
       "      <th>node_memory_usage</th>\n",
       "      <th>pod_lifetime_seconds</th>\n",
       "      <th>memory_usage</th>\n",
       "      <th>cpu_limit</th>\n",
       "      <th>memory_limit</th>\n",
       "      <th>cpu_usage</th>\n",
       "      <th>cpu_request</th>\n",
       "      <th>memory_request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "      <td>15000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2023-01-01 02:04:30</td>\n",
       "      <td>0.500843</td>\n",
       "      <td>0.501448</td>\n",
       "      <td>499.580661</td>\n",
       "      <td>99.811810</td>\n",
       "      <td>60.087796</td>\n",
       "      <td>49.390820</td>\n",
       "      <td>50.163728</td>\n",
       "      <td>100122.210267</td>\n",
       "      <td>4123.388369</td>\n",
       "      <td>2.250631</td>\n",
       "      <td>4234.132709</td>\n",
       "      <td>1.994210</td>\n",
       "      <td>1.052096</td>\n",
       "      <td>2110.281025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2023-01-01 00:00:00</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.090925</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>20.000494</td>\n",
       "      <td>0.022562</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0.500025</td>\n",
       "      <td>256.212641</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.100021</td>\n",
       "      <td>128.119738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2023-01-01 01:02:00</td>\n",
       "      <td>0.252717</td>\n",
       "      <td>0.249897</td>\n",
       "      <td>250.814566</td>\n",
       "      <td>49.599228</td>\n",
       "      <td>40.059461</td>\n",
       "      <td>24.448180</td>\n",
       "      <td>25.184379</td>\n",
       "      <td>50425.750000</td>\n",
       "      <td>2099.208569</td>\n",
       "      <td>1.378411</td>\n",
       "      <td>2281.175714</td>\n",
       "      <td>0.989391</td>\n",
       "      <td>0.575561</td>\n",
       "      <td>1127.360048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2023-01-01 02:04:30</td>\n",
       "      <td>0.501555</td>\n",
       "      <td>0.499775</td>\n",
       "      <td>497.133849</td>\n",
       "      <td>99.046093</td>\n",
       "      <td>60.000056</td>\n",
       "      <td>49.266834</td>\n",
       "      <td>50.032371</td>\n",
       "      <td>99422.500000</td>\n",
       "      <td>4120.838924</td>\n",
       "      <td>2.251391</td>\n",
       "      <td>4212.613405</td>\n",
       "      <td>1.998167</td>\n",
       "      <td>1.055143</td>\n",
       "      <td>2097.534763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-01-01 03:07:00</td>\n",
       "      <td>0.747617</td>\n",
       "      <td>0.752850</td>\n",
       "      <td>747.535380</td>\n",
       "      <td>150.549303</td>\n",
       "      <td>80.126939</td>\n",
       "      <td>73.929835</td>\n",
       "      <td>75.417713</td>\n",
       "      <td>149846.250000</td>\n",
       "      <td>6189.240921</td>\n",
       "      <td>3.125031</td>\n",
       "      <td>6211.191332</td>\n",
       "      <td>2.988054</td>\n",
       "      <td>1.527721</td>\n",
       "      <td>3098.478331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-01-01 04:09:00</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>999.919897</td>\n",
       "      <td>199.998813</td>\n",
       "      <td>99.981225</td>\n",
       "      <td>99.996519</td>\n",
       "      <td>99.999938</td>\n",
       "      <td>199968.000000</td>\n",
       "      <td>8191.874733</td>\n",
       "      <td>3.999600</td>\n",
       "      <td>8191.858882</td>\n",
       "      <td>3.999931</td>\n",
       "      <td>1.999917</td>\n",
       "      <td>4095.689412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.288213</td>\n",
       "      <td>0.289830</td>\n",
       "      <td>287.769516</td>\n",
       "      <td>57.929142</td>\n",
       "      <td>23.112204</td>\n",
       "      <td>28.774625</td>\n",
       "      <td>28.940546</td>\n",
       "      <td>57502.260644</td>\n",
       "      <td>2365.471215</td>\n",
       "      <td>1.010891</td>\n",
       "      <td>2282.287735</td>\n",
       "      <td>1.155110</td>\n",
       "      <td>0.548135</td>\n",
       "      <td>1144.993437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp  cpu_allocation_efficiency  \\\n",
       "count                15000               15000.000000   \n",
       "mean   2023-01-01 02:04:30                   0.500843   \n",
       "min    2023-01-01 00:00:00                   0.000165   \n",
       "25%    2023-01-01 01:02:00                   0.252717   \n",
       "50%    2023-01-01 02:04:30                   0.501555   \n",
       "75%    2023-01-01 03:07:00                   0.747617   \n",
       "max    2023-01-01 04:09:00                   0.999957   \n",
       "std                    NaN                   0.288213   \n",
       "\n",
       "       memory_allocation_efficiency       disk_io  network_latency  \\\n",
       "count                  15000.000000  15000.000000     15000.000000   \n",
       "mean                       0.501448    499.580661        99.811810   \n",
       "min                        0.000078      0.090925         0.000564   \n",
       "25%                        0.249897    250.814566        49.599228   \n",
       "50%                        0.499775    497.133849        99.046093   \n",
       "75%                        0.752850    747.535380       150.549303   \n",
       "max                        0.999960    999.919897       199.998813   \n",
       "std                        0.289830    287.769516        57.929142   \n",
       "\n",
       "       node_temperature  node_cpu_usage  node_memory_usage  \\\n",
       "count      15000.000000    15000.000000       15000.000000   \n",
       "mean          60.087796       49.390820          50.163728   \n",
       "min           20.000494        0.022562           0.009563   \n",
       "25%           40.059461       24.448180          25.184379   \n",
       "50%           60.000056       49.266834          50.032371   \n",
       "75%           80.126939       73.929835          75.417713   \n",
       "max           99.981225       99.996519          99.999938   \n",
       "std           23.112204       28.774625          28.940546   \n",
       "\n",
       "       pod_lifetime_seconds  memory_usage     cpu_limit  memory_limit  \\\n",
       "count          15000.000000  15000.000000  15000.000000  15000.000000   \n",
       "mean          100122.210267   4123.388369      2.250631   4234.132709   \n",
       "min                6.000000      0.012189      0.500025    256.212641   \n",
       "25%            50425.750000   2099.208569      1.378411   2281.175714   \n",
       "50%            99422.500000   4120.838924      2.251391   4212.613405   \n",
       "75%           149846.250000   6189.240921      3.125031   6211.191332   \n",
       "max           199968.000000   8191.874733      3.999600   8191.858882   \n",
       "std            57502.260644   2365.471215      1.010891   2282.287735   \n",
       "\n",
       "          cpu_usage   cpu_request  memory_request  \n",
       "count  15000.000000  15000.000000    15000.000000  \n",
       "mean       1.994210      1.052096     2110.281025  \n",
       "min        0.000521      0.100021      128.119738  \n",
       "25%        0.989391      0.575561     1127.360048  \n",
       "50%        1.998167      1.055143     2097.534763  \n",
       "75%        2.988054      1.527721     3098.478331  \n",
       "max        3.999931      1.999917     4095.689412  \n",
       "std        1.155110      0.548135     1144.993437  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6cccc724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleaning (in critical numeric columns):\n",
      "cpu_limit               0\n",
      "memory_limit            0\n",
      "cpu_request             0\n",
      "memory_request          0\n",
      "cpu_usage               0\n",
      "memory_usage            0\n",
      "node_cpu_usage          0\n",
      "node_memory_usage       0\n",
      "disk_io                 0\n",
      "network_latency         0\n",
      "node_temperature        0\n",
      "pod_lifetime_seconds    0\n",
      "dtype: int64\n",
      "\n",
      "0 rows dropped due to missing cpu_limit or memory_limit.\n"
     ]
    }
   ],
   "source": [
    "critical_cols = ['cpu_limit', 'memory_limit', 'cpu_request', 'memory_request', \n",
    "    'cpu_usage', 'memory_usage', \n",
    "    'node_cpu_usage', 'node_memory_usage', 'disk_io', 'network_latency', \n",
    "    'node_temperature', 'pod_lifetime_seconds']\n",
    "\n",
    "print(\"Missing values before cleaning (in critical numeric columns):\")\n",
    "print(df_cleaned[critical_cols].isnull().sum())\n",
    "\n",
    "rows_before = len(df_cleaned)\n",
    "df_cleaned.dropna(subset=critical_cols, inplace=True)\n",
    "\n",
    "rows_dropped = rows_before - len(df_cleaned)\n",
    "print(f\"\\n{rows_dropped} rows dropped due to missing cpu_limit or memory_limit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "77cdb3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows remaining after cleanup: 15000\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df_cleaned.select_dtypes(include=np.number).columns\n",
    "df_cleaned.loc[:, numeric_cols] = df_cleaned.loc[:, numeric_cols].clip(lower=0)\n",
    "\n",
    "print(f\"Rows remaining after cleanup: {len(df_cleaned)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798cae0a",
   "metadata": {},
   "source": [
    "### 3.2 Identifying and Handling Duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "209df565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9a4e0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_metrics = ['disk_io', 'network_latency', 'node_temperature', \n",
    "                    'node_cpu_usage', 'node_memory_usage']\n",
    "\n",
    "# Cap any negative values at 0 for these columns\n",
    "df_cleaned.loc[:, physical_metrics] = df_cleaned[physical_metrics].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81504662",
   "metadata": {},
   "source": [
    "### 3.4 Binary Classification- Target Defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_messages = ['Killed', 'OOMKilled']\n",
    "\n",
    "# 1 if the event message is one of the critical failures, 0 otherwise.\n",
    "target = df_cleaned['event_message'].isin(critical_messages).astype(int)\n",
    "\n",
    "# Adding the target back to the DataFrame for alignment and viewing\n",
    "df_cleaned.loc[:,'Resource_Overload_Flag'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "527d3dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_message\n",
       "0    9117\n",
       "1    5883\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f856e",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4541a62e",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33245f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final= df_cleaned.copy() # Starting a new, final DataFrame for modeling prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "302bc069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['timestamp', 'pod_name', 'namespace', 'cpu_allocation_efficiency', 'memory_allocation_efficiency', 'disk_io', 'network_latency', 'node_temperature', 'node_cpu_usage', 'node_memory_usage', 'event_type', 'event_message', 'scaling_event', 'pod_lifetime_seconds', 'memory_usage', 'cpu_limit', 'memory_limit', 'cpu_usage', 'deployment_strategy', 'scaling_policy', 'cpu_request', 'memory_request', 'Resource_Overload_Flag']\n"
     ]
    }
   ],
   "source": [
    "print(df_final.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a7b81",
   "metadata": {},
   "source": [
    "### 5.1 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8bb37abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[:, 'cpu_utilization_ratio'] = df_final['cpu_usage'] / df_final['cpu_limit']\n",
    "df_final.loc[:, 'memory_utilization_ratio'] = df_final['memory_usage'] / df_final['memory_limit']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab987e",
   "metadata": {},
   "source": [
    "### 5.2 Outlier Treatment (Clipping the key ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f2245f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap the extreme outliers in the utilization ratio at the 99th percentile \n",
    "# to stabilize linear models and manage high leverage points.\n",
    "cpu_ratio_cap = df_final['cpu_utilization_ratio'].quantile(0.99)\n",
    "\n",
    "df_final.loc[:, 'cpu_utilization_ratio'] = df_final['cpu_utilization_ratio'].clip(upper=cpu_ratio_cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa577750",
   "metadata": {},
   "source": [
    "### 5.3 One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "682c333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['namespace', 'deployment_strategy', 'scaling_policy']\n",
    "df_final = pd.get_dummies(df_final, columns=categorical_features, drop_first=True, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2b4992",
   "metadata": {},
   "source": [
    "### 5.4 Final Feature (X) and Target (y) Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a5c639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of observations (rows): 15000\n",
      "Final number of features (X columns): 19\n"
     ]
    }
   ],
   "source": [
    "y = target\n",
    "\n",
    "features_to_keep = [\n",
    "    'cpu_limit', 'memory_limit', 'cpu_request', 'memory_request',\n",
    "    'cpu_utilization_ratio', 'memory_utilization_ratio', \n",
    "    'cpu_allocation_efficiency', # <--- The critical addition\n",
    "    'memory_allocation_efficiency', # <--- The critical addition\n",
    "    'node_cpu_usage', 'node_memory_usage', 'disk_io', 'network_latency', \n",
    "    'node_temperature', 'pod_lifetime_seconds'\n",
    "]\n",
    "\n",
    "\n",
    "X = df_final[features_to_keep + list(df_final.filter(regex='_policy|_strategy|namespace_').columns)]\n",
    "\n",
    "print(f\"Final number of observations (rows): {X.shape[0]}\")\n",
    "print(f\"Final number of features (X columns): {X.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daadfbd8",
   "metadata": {},
   "source": [
    "## 6. Model Building and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfbd457",
   "metadata": {},
   "source": [
    "### 6.1 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "73d41a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8bdbaa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 10500 rows\n",
      "Test set size: 4500 rows\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=random_seed, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {X_train.shape[0]} rows\")\n",
    "print(f\"Test set size: {X_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdf4309",
   "metadata": {},
   "source": [
    "### 6.2 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f0ddf178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and Apply the StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    " # Fit only on the training data\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "# Transform both train and test data\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb4d0f",
   "metadata": {},
   "source": [
    "### 6.3 Model Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75683d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Finished training and predicting with: lr\n",
      "-> Finished training and predicting with: dtc\n",
      "-> Finished training and predicting with: rfc\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# Initialize Models\n",
    "models = {\n",
    "    \"lr\": LogisticRegression(random_state=random_seed, solver='liblinear', class_weight='balanced'),\n",
    "    \"dtc\": DecisionTreeClassifier(random_state=random_seed),\n",
    "    \"rfc\": RandomForestClassifier(random_state=random_seed),\n",
    "  }\n",
    "\n",
    "# Training and Prediction Loop\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    if name == 'lr':\n",
    "        # Use scaled data for Logistic Regression\n",
    "        model.fit(X_train_scaled, y_train) \n",
    "        Y_pred = model.predict(X_test_scaled)\n",
    "        # Use predict_proba for ROC-AUC\n",
    "        Y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        # Use unscaled data for Tree Models (they are scale-invariant)\n",
    "        model.fit(X_train, y_train) \n",
    "        Y_pred = model.predict(X_test)\n",
    "        Y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    results[name] = {'Y_pred': Y_pred, 'Y_proba': Y_proba, 'model': model}\n",
    "    print(f\"-> Finished training and predicting with: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b6836",
   "metadata": {},
   "source": [
    "### 6.3 Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019c6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance Comparison ---\n",
      "| Model   |   Accuracy |   Precision (Class 1) |   Recall (Class 1) |   F1-Score (Class 1) |   ROC-AUC |\n",
      "|:--------|-----------:|----------------------:|-------------------:|---------------------:|----------:|\n",
      "| rfc     |     0.5949 |                0.3942 |             0.0612 |               0.1059 |    0.5039 |\n",
      "| dtc     |     0.524  |                0.3965 |             0.4091 |               0.4027 |    0.5036 |\n",
      "| lr      |     0.5011 |                0.3919 |             0.4929 |               0.4366 |    0.4997 |\n",
      "\n",
      "Top 10 Feature Importances for rfc:\n",
      "|                              |         0 |\n",
      "|:-----------------------------|----------:|\n",
      "| memory_allocation_efficiency | 0.0697751 |\n",
      "| network_latency              | 0.0697731 |\n",
      "| cpu_allocation_efficiency    | 0.0695826 |\n",
      "| node_memory_usage            | 0.0688667 |\n",
      "| disk_io                      | 0.0688294 |\n",
      "| node_cpu_usage               | 0.0687798 |\n",
      "| pod_lifetime_seconds         | 0.0685631 |\n",
      "| memory_request               | 0.0682548 |\n",
      "| cpu_limit                    | 0.0681848 |\n",
      "| node_temperature             | 0.0680125 |\n"
     ]
    }
   ],
   "source": [
    "comparison_metrics = []\n",
    "\n",
    "for name, data in results.items():\n",
    "    # Classification Report\n",
    "    report = classification_report(y_test, data['Y_pred'], output_dict=True, zero_division=0)\n",
    "    \n",
    "    metrics_1 = report.get('1', {}) # Get '1' key, or an empty dict {} if not present\n",
    "\n",
    "    precision = metrics_1.get('precision', 0.0)\n",
    "    recall = metrics_1.get('recall', 0.0)\n",
    "    f1 = metrics_1.get('f1-score', 0.0)\n",
    "    \n",
    "    # Overall Metrics\n",
    "    accuracy = report['accuracy']\n",
    "    roc_auc = roc_auc_score(y_test, data['Y_proba'])\n",
    "\n",
    "    comparison_metrics.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': np.round(accuracy, 4),\n",
    "        'Precision (Class 1)': np.round(precision, 4),\n",
    "        'Recall (Class 1)': np.round(recall, 4),\n",
    "        'F1-Score (Class 1)': np.round(f1, 4),\n",
    "        'ROC-AUC': np.round(roc_auc, 4)\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(comparison_metrics).sort_values(by='ROC-AUC', ascending=False)\n",
    "\n",
    "print(\"\\n--- Model Performance Comparison ---\")\n",
    "print(df_metrics.to_markdown(index=False))\n",
    "# \n",
    "\n",
    "# Feature Importance \n",
    "best_model_name = df_metrics.iloc[0]['Model']\n",
    "\n",
    "if best_model_name in [\"rfc\", \"dtc\"]:\n",
    "    best_model = results[best_model_name]['model']\n",
    "    feature_importances = pd.Series(best_model.feature_importances_, index=X.columns).sort_values(ascending=False).head(10)\n",
    "    print(f\"\\nTop 10 Feature Importances for {best_model_name}:\")\n",
    "    print(feature_importances.to_markdown())\n",
    "    #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da50f54",
   "metadata": {},
   "source": [
    "### 6.4 Model Evaluation and Selection\n",
    "Comparison Table: Present a table comparing all models using Accuracy, Precision, Recall, F1-score, and ROC-AUC. Selection: State which model performs best for your goal (likely optimizing for high Recall to avoid missing a scaling event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add632e7",
   "metadata": {},
   "source": [
    "## 7. Results and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df44b2a",
   "metadata": {},
   "source": [
    "## 8. Conclusion and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b669a973",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8ab2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
